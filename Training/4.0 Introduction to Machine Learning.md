# Introduction to Machine Learning

Many of you might have heard of machine learning before, some of you might have even used it! Here we will start with the basics. First we need to know what machine learning is and WHY would we want to use it in Data Science.

### Task 1: 

There are 2 main types of machine learning tasks; supervirsed learning and unsupervirsed learning. Research what the main differences between these and what tasks they might be useful for.

```
Supervised learning is a machine learning approach by its use of labeled dataset. This learning can be used with classification and regression.
However, unsupervised learning is the machine use algorithms to analyze and cluster unlabeled dataset. This learning can be used for clustering, association and dimensionality.
```

To start us of with we will be using a supervirsed machine learning method. One of simplest methods is the k-Nearest Neighbors. 


### Task 2

Research the k-Nearest Neighbors algortihtm and how it can be used for classification and regression models, detail your findings below. 

Useful links to start you off with:
[Neighbors Classification](https://scikit-learn.org/stable/modules/neighbors.html#classification) , 
[Plotting](https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py).

```
Neighbors-based classification is a type of instance-based learning or non-generalizing learning; it stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point. Scikit-learn implements two different nearest neighbors classifiers: KNeighborsClassifier and RadiusNeighborsClassifier.  KNeighborsClassifier implements learning based on the k nearest neighbors of each query point, where k is an integer. RadiusNeighborsClassifier implements learning based on the number of neighbors within a fixed radius r of each training poin, where r is float.

Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. Scikit-learn implements two different neighbors regressors: KNeighborsRegressor and RadiusNeighborsRegressor. KNeighborsRegressor implements learning based on the k nearest neighbors of each query point, where k is an integer value specified by the user. RadiusNeighborsRegressor implements learning based on the neighbors within a fixed radius r of the query point, where r is a floating-point value specified by the user.
```

As you may have noticed k-Neares Neighbors is within the scikit-learn library. This is the most prominent machine learning library in Python and contains state-of the art machine learning methods! You can find a lot of information on their [website](https://scikit-learn.org/stable/) so make sure to keep that handy! 
Now we will be implementing our classification algorithm! 

### Task 3: 

Following the example detailed in the [scikit website](https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py).

Import all functionalities from libraries needed as well as the dataset. First, visualize the iris dataset! What do each of the columns in the data represent?

Then run the code. First plot the boundaries defined by the model without the training data on the plot. Then add the training data to your plot. 

```
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import ListedColormap
from sklearn import neighbors, datasets
from sklearn.inspection import DecisionBoundaryDisplay

n_neighbors = 15

iris = datasets.load_iris()

X = iris.data[:, :2]
y = iris.target

xmin, xmax = X:[, 0].min()-1, X:[, 0].max()+1
ymin, ymax = X:[, 1].min()-1, X:[, 1].max()+1

sns.scatterplot(
  a = X[:,0],
  b = X[:,1],
  alpha = 1.0
)
plt.xlabel(iris.feature_names[0])
plt.ylabel(iris.feature_names[1])
plt.show()
```

### This is the end of this training exercise. In order to become proficient with these methodologies you will need PRACTICE! So make sure to look at examples on the scikit-learn website and run the codes yourself!
