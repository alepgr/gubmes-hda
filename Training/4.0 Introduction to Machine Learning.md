# Introduction to Machine Learning

Many of you might have heard of machine learning before, some of you might have even used it! Here we will start with the basics. First we need to know what machine learning is and WHY would we want to use it in Data Science.

### Task 1: 

There are 2 main types of machine learning tasks; supervirsed learning and unsupervirsed learning. Research what the main differences between these and what tasks they might be useful for.

```
Supervised learning uses labelled data sets to teach an algorithmm to recognise certain patterns in data inputs. Unsupervised learning uses unlabelled sets to teach an algorithm to recognise patterns that are inhenerntly within the data set.
```

To start us of with we will be using a supervirsed machine learning method. One of simplest methods is the k-Nearest Neighbors. 


### Task 2

Research the k-Nearest Neighbors algortihtm and how it can be used for classification and regression models, detail your findings below. 

Useful links to start you off with:
[Neighbors Classification](https://scikit-learn.org/stable/modules/neighbors.html#classification) , 
[Plotting](https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py).

```
It is an algorithm that takes the assumption that similar data points will be close to each other and uses its taught data sets to classify new datapoints according to the classifications of its nearest neighbours.
```

As you may have noticed k-Neares Neighbors is within the scikit-learn library. This is the most prominent machine learning library in Python and contains state-of the art machine learning methods! You can find a lot of information on their [website](https://scikit-learn.org/stable/) so make sure to keep that handy! 
Now we will be implementing our classification algorithm! 

### Task 3: 

Following the example detailed in the [scikit website](https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py).

Import all functionalities from libraries needed as well as the dataset. First, visualize the iris dataset! What do each of the columns in the data represent?

Then run the code. First plot the boundaries defined by the model without the training data on the plot. Then add the training data to your plot. 

```py
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import ListedColormap
from sklearn import neighbors, datasets
from sklearn.inspection import DecisionBoundaryDisplay

n_neighbors = 15

# import some data to play with
iris = datasets.load_iris()

# we only take the first two features. We could avoid this ugly
# slicing by using a two-dim dataset
X = iris.data[:, :2]
y = iris.target

# Create color maps
cmap_light = ListedColormap(["orange", "cyan", "cornflowerblue"])
cmap_bold = ["darkorange", "c", "darkblue"]

for weights in ["uniform", "distance"]:
    # we create an instance of Neighbours Classifier and fit the data.
    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)
    clf.fit(X, y)

    _, ax = plt.subplots()
    DecisionBoundaryDisplay.from_estimator(
        clf,
        X,
        cmap=cmap_light,
        ax=ax,
        response_method="predict",
        plot_method="pcolormesh",
        xlabel=iris.feature_names[0],
        ylabel=iris.feature_names[1],
        shading="auto",
    )

    # Plot also the training points
    sns.scatterplot(
        x=X[:, 0],
        y=X[:, 1],
        hue=iris.target_names[y],
        palette=cmap_bold,
        alpha=1.0,
        edgecolor="black",
    )
    plt.title(
        "3-Class classification (k = %i, weights = '%s')" % (n_neighbors, weights)
    )

plt.show()
```

### This is the end of this training exercise. In order to become proficient with these methodologies you will need PRACTICE! So make sure to look at examples on the scikit-learn website and run the codes yourself!
